# Gesture-Dataset
We make a gesture dataset by using mobile phone capture and OpenCV library calling local camera capture. In different scenarios, various methods are used to enhance the diversity of samples, such as different people turning the angle during the shooting process, deforming the fingers, adjusting the distance between the gesture and the local camera, etc. The self-made dataset in this study collected gestures from 54 people, each with 26 gestures. These 26 gestures represent the 26 letters A to Z of American Sign Language (ASL) gestures. There are 106 samples in each category, and a total of 2756 gesture samples.
